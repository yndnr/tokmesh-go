# TokMesh ä»£ç å®¡æ ¸æŠ¥å‘Š

**æ¨¡å—**: `src/internal/server/clusterserver`
**å®¡æ ¸æ—¥æœŸ**: 2025-12-22
**å®¡æ ¸äºº**: Claude Sonnet 4.5
**å®¡æ ¸æ¡†æ¶ç‰ˆæœ¬**: audit-framework.md v1.1
**å®¡æ ¸èŒƒå›´**: å…¨é‡ä»£ç å®¡æ ¸ï¼ˆ9ä¸ªç”Ÿäº§æ–‡ä»¶ï¼Œ~2500è¡Œä»£ç ï¼‰

---

## ğŸ“Š å®¡æ ¸æ‘˜è¦

**æ€»ä½“è¯„åˆ†**: 72/100
**é£é™©ç­‰çº§**: **ä¸­å±**
**é—®é¢˜ç»Ÿè®¡**:
- **[ä¸¥é‡]**: 8 ä¸ªï¼ˆè§„çº¦ä¸ä¸€è‡´ã€å®‰å…¨æ¼æ´ã€å¹¶å‘é—®é¢˜ï¼‰
- **[è­¦å‘Š]**: 12 ä¸ªï¼ˆè¾¹ç•Œæ ¡éªŒã€é”™è¯¯å¤„ç†ã€èµ„æºæ³„æ¼ï¼‰
- **[å»ºè®®]**: 7 ä¸ªï¼ˆé­”æœ¯å€¼ã€ä»£ç è§„èŒƒï¼‰

**æ ¸å¿ƒå‘ç°**:
1. âŒ **è§„çº¦å¯¹é½ä¸¥é‡åå·®**: è™šæ‹ŸèŠ‚ç‚¹æ•°ã€å“ˆå¸Œç®—æ³•ä¸ DS-0401 è®¾è®¡ä¸ä¸€è‡´
2. âŒ **å®‰å…¨æ€§ç¼ºé™·**: mTLS è®¤è¯æœªå®Œæ•´å®ç°ï¼Œç”Ÿäº§ç¯å¢ƒ TLS é…ç½®ç¼ºå¤±
3. âš ï¸ **å¹¶å‘å®‰å…¨éšæ‚£**: Goroutine æ³„æ¼é£é™©ã€Channel é˜»å¡é£é™©
4. âš ï¸ **è¾¹ç•Œæ ¡éªŒä¸è¶³**: å¤šå¤„å‚æ•°æœªæ ¡éªŒã€nil æ£€æŸ¥ç¼ºå¤±

---

## âŒ ä¸¥é‡é—®é¢˜ (Critical Issues)

### [ä¸¥é‡-01] è™šæ‹ŸèŠ‚ç‚¹æ•°ä¸è®¾è®¡æ–‡æ¡£ä¸ä¸€è‡´

**ä½ç½®**: `src/internal/server/clusterserver/shard.go:18`

**åˆ†æ**:
- **è®¾è®¡è¦æ±‚** (DS-0401, RQ-0401): æ¯ä¸ªç‰©ç†èŠ‚ç‚¹å¯¹åº” **256 ä¸ª**è™šæ‹ŸèŠ‚ç‚¹
- **å®é™…ä»£ç **: `DefaultVirtualNodeCount = 100`
- **å½±å“**: æ•°æ®å€¾æ–œé£é™©å¢åŠ ï¼Œè´Ÿè½½å‡è¡¡æ•ˆæœä¸è¾¾é¢„æœŸ

**å»ºè®®**:
```go
const (
    DefaultShardCount = 256
    DefaultVirtualNodeCount = 256  // ä¿®æ”¹ä¸º 256 (ä¸ DS-0401 ä¸€è‡´)
)
```

**å¼•ç”¨**: `@design DS-0401 Â§ 1.2 æ•°æ®åˆ†ç‰‡`

---

### [ä¸¥é‡-02] å“ˆå¸Œç®—æ³•ä¸è®¾è®¡æ–‡æ¡£ä¸ä¸€è‡´

**ä½ç½®**: `src/internal/server/clusterserver/shard.go:82-87`

**åˆ†æ**:
- **è®¾è®¡è¦æ±‚** (RQ-0401): ä½¿ç”¨ **MurmurHash3**
- **å®é™…ä»£ç **: ä½¿ç”¨ **FNV-1a** (`fnv.New32a()`, `fnv.New64a()`)
- **å½±å“**:
  - å“ˆå¸Œåˆ†å¸ƒç‰¹æ€§ä¸è®¾è®¡é¢„æœŸä¸ç¬¦
  - è¿ç§»æ—¶æ•°æ®è·¯ç”±å¯èƒ½å‡ºé”™
  - è·¨ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜

**å»ºè®®**:
```go
import "github.com/spaolacci/murmur3"

func (m *ShardMap) HashKey(key string) uint32 {
    return murmur3.Sum32([]byte(key)) % DefaultShardCount
}

func (m *ShardMap) hashVirtualNode(nodeID string, virtualIndex int) uint64 {
    h := murmur3.New64()
    h.Write([]byte(nodeID))
    // ... virtualIndex ç¼–ç 
    return h.Sum64()
}
```

**å¼•ç”¨**: `@req RQ-0401 Â§ 1.1 æ•°æ®åˆ†ç‰‡ - å“ˆå¸Œå‡½æ•°`

---

### [ä¸¥é‡-03] ç¼ºå°‘ Cluster ID æ ¡éªŒæœºåˆ¶

**ä½ç½®**: `src/internal/server/clusterserver/discovery.go:51-112`

**åˆ†æ**:
- **è®¾è®¡è¦æ±‚** (RQ-0401 Â§ 1.2): èŠ‚ç‚¹æ¡æ‰‹æ—¶å¿…é¡»æ ¡éªŒ Cluster IDï¼Œé˜²æ­¢é”™è¯¯åˆå¹¶
- **å®é™…ä»£ç **: `NewDiscovery()` æœªå®ç° Cluster ID éªŒè¯é€»è¾‘
- **å½±å“**:
  - **è„‘è£‚é£é™©**: ç½‘ç»œåˆ†åŒºåä¸¤ä¸ªé›†ç¾¤å¯èƒ½é”™è¯¯åˆå¹¶
  - **æ•°æ®æ··ä¹±**: ä¸åŒé›†ç¾¤çš„æ•°æ®å¯èƒ½è¢«æ··åˆ

**å»ºè®®**:
```go
type DiscoveryConfig struct {
    NodeID    string
    ClusterID string  // æ–°å¢ï¼šé›†ç¾¤å”¯ä¸€æ ‡è¯†
    // ...
}

// åœ¨ eventDelegate.NotifyJoin ä¸­éªŒè¯
func (e *eventDelegate) NotifyJoin(node *memberlist.Node) {
    // è§£æ Meta ä¸­çš„ ClusterID
    meta := parseMetadata(node.Meta)
    if meta.ClusterID != e.discovery.clusterID {
        e.discovery.logger.Error("cluster ID mismatch - rejecting node",
            "node_id", node.Name,
            "expected_cluster_id", e.discovery.clusterID,
            "actual_cluster_id", meta.ClusterID)
        // æ‹’ç»èŠ‚ç‚¹åŠ å…¥
        return
    }
    // ...
}
```

**å¼•ç”¨**: `@req RQ-0401 Â§ 1.2 èŠ‚ç‚¹å‘ç° - é›†ç¾¤æ ‡è¯† (Cluster ID)`

---

### [ä¸¥é‡-04] mTLS è®¤è¯æœªå®Œæ•´å®ç°

**ä½ç½®**: `src/internal/server/clusterserver/interceptor.go:246-267`

**åˆ†æ**:
- `extractTLSInfo()` å§‹ç»ˆè¿”å›é”™è¯¯ `"cannot extract TLS connection state from peer"`
- Context value æŸ¥è¯¢ `ctx.Value("tls.ConnectionState")` ä¸æ˜¯ Connect æ¡†æ¶æ ‡å‡†æ–¹å¼
- **å½±å“**:
  - **ç”Ÿäº§ç¯å¢ƒæ— æ³•é‰´æƒ**: èŠ‚ç‚¹é—´æ— æ³•éªŒè¯èº«ä»½
  - **å®‰å…¨æ€§å½’é›¶**: ä»»ä½•èŠ‚ç‚¹éƒ½å¯ä»¥å†’å……åŠ å…¥é›†ç¾¤

**å»ºè®®**:
```go
// ä½¿ç”¨ Connect æ¡†æ¶æ­£ç¡®æ–¹å¼è·å– TLS çŠ¶æ€
func (i *AuthInterceptor) extractTLSInfo(ctx context.Context, peer connect.Peer) (*tls.ConnectionState, error) {
    // æ–¹æ¡ˆ1: ä» peer.Protocol åˆ¤æ–­æ˜¯å¦ä¸º TLS
    // æ–¹æ¡ˆ2: ä½¿ç”¨ Connect æä¾›çš„ metadata æˆ–è‡ªå®šä¹‰ä¸Šä¸‹æ–‡é”®
    // æ–¹æ¡ˆ3: åœ¨ HTTP Handler å±‚é¢æ³¨å…¥ TLS çŠ¶æ€åˆ° Context

    // ä¸´æ—¶æ–¹æ¡ˆï¼ˆéœ€éªŒè¯ï¼‰:
    if info, ok := peer.Query("tls.ConnectionState").(*tls.ConnectionState); ok {
        return info, nil
    }

    return nil, errors.New("TLS not configured")
}
```

**è¡ŒåŠ¨**:
1. æŸ¥é˜… Connect RPC æ–‡æ¡£ç¡®è®¤ TLS state æå–æ–¹å¼
2. å®ç°æ­£ç¡®çš„ mTLS éªŒè¯é€»è¾‘
3. æ·»åŠ é›†æˆæµ‹è¯•éªŒè¯ mTLS å·¥ä½œ

**å¼•ç”¨**: `@design DS-0401 Â§ 2.1 æ¶æ„åˆ†å±‚å›¾ - mTLS é€šä¿¡`

---

### [ä¸¥é‡-05] ç”Ÿäº§ç¯å¢ƒ TLS é…ç½®ç¼ºå¤±

**ä½ç½®**: `src/internal/server/clusterserver/server.go:614-617`

**åˆ†æ**:
```go
// TODO: Configure TLS for production deployments
httpClient := &http.Client{
    Timeout: 30 * time.Second,
}
```

- **å½±å“**:
  - é›†ç¾¤é—´é€šä¿¡ä½¿ç”¨ **æ˜æ–‡ HTTP**
  - Token/Session æ•°æ®åœ¨ç½‘ç»œä¸­æš´éœ²
  - è¿åè®¾è®¡æ–‡æ¡£ mTLS è¦æ±‚

**å»ºè®®**:
```go
func (s *Server) createRPCClient(addr string) (clusterv1connect.ClusterServiceClient, error) {
    // åŠ è½½é›†ç¾¤ TLS é…ç½®
    tlsConfig, err := s.loadClusterTLSConfig()
    if err != nil {
        return nil, fmt.Errorf("load TLS config: %w", err)
    }

    httpClient := &http.Client{
        Timeout: 30 * time.Second,
        Transport: &http.Transport{
            TLSClientConfig: tlsConfig,
        },
    }

    baseURL := fmt.Sprintf("https://%s", addr)  // ä½¿ç”¨ HTTPS
    client := clusterv1connect.NewClusterServiceClient(httpClient, baseURL, connect.WithGRPC())
    return client, nil
}
```

**å¼•ç”¨**: `@req RQ-0401 Â§ 3.1.3 - cluster.tls.*`

---

### [ä¸¥é‡-06] Goroutine æ³„æ¼é£é™©

**ä½ç½®**: `src/internal/server/clusterserver/server.go:535-546`

**åˆ†æ**:
```go
go func() {
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
    defer cancel()

    time.Sleep(5 * time.Second)

    if err := s.rebalanceManager.TriggerRebalance(ctx, currentMap, currentMap); err != nil {
        s.logger.Error("auto-rebalance failed", "error", err)
    }
}()
```

- **é—®é¢˜**:
  - åŒ¿å Goroutine æœªè¢« `stopCh` æ§åˆ¶ï¼ŒServer.Stop() æ—¶æ— æ³•ä¼˜é›…é€€å‡º
  - 30åˆ†é’Ÿè¶…æ—¶æœŸé—´ï¼ŒServer å¯èƒ½å·²åœæ­¢ä½† Goroutine ä»è¿è¡Œ
- **å½±å“**: èµ„æºæ³„æ¼ã€æµ‹è¯•ç¯å¢ƒ Goroutine å †ç§¯

**å»ºè®®**:
```go
go func() {
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
    defer cancel()

    select {
    case <-time.After(5 * time.Second):
        // ç»§ç»­æ‰§è¡Œ
    case <-s.stopCh:
        s.logger.Info("rebalance cancelled - server stopping")
        return
    }

    // ä½¿ç”¨å¯å–æ¶ˆçš„ context
    rebalanceCtx, rebalanceCancel := context.WithCancel(ctx)
    defer rebalanceCancel()

    go func() {
        <-s.stopCh
        rebalanceCancel()  // Server åœæ­¢æ—¶å–æ¶ˆ rebalance
    }()

    if err := s.rebalanceManager.TriggerRebalance(rebalanceCtx, currentMap, currentMap); err != nil {
        // ...
    }
}()
```

---

### [ä¸¥é‡-07] Channel åŒé‡å…³é—­é£é™©

**ä½ç½®**: `src/internal/server/clusterserver/discovery.go:139-153`

**åˆ†æ**:
```go
func (d *Discovery) Shutdown() error {
    if d.shutdown || d.memberList == nil {
        return nil
    }

    d.shutdown = true  // éåŸå­æ“ä½œ

    // ...
    close(d.events)  // å¯èƒ½è¢«å¹¶å‘è°ƒç”¨
    // ...
}
```

- **é—®é¢˜**:
  - `d.shutdown` æ ‡å¿—éåŸå­æ“ä½œï¼Œå¹¶å‘è°ƒç”¨æ—¶å¯èƒ½åŒé‡å…³é—­ `d.events`
  - **Panic é£é™©**: `close of closed channel`
- **è§¦å‘åœºæ™¯**: Server.Stop() å’Œå¤–éƒ¨ Shutdown() åŒæ—¶è°ƒç”¨

**å»ºè®®**:
```go
import "sync/atomic"

type Discovery struct {
    // ...
    shutdown atomic.Bool  // ä½¿ç”¨ atomic.Bool (Go 1.19+)
}

func (d *Discovery) Shutdown() error {
    // CAS æ“ä½œç¡®ä¿åªå…³é—­ä¸€æ¬¡
    if !d.shutdown.CompareAndSwap(false, true) {
        return nil  // å·²ç»å…³é—­
    }

    if d.memberList == nil {
        return nil
    }

    if err := d.memberList.Shutdown(); err != nil {
        return fmt.Errorf("shutdown memberlist: %w", err)
    }

    close(d.events)
    d.logger.Info("discovery shutdown complete")
    return nil
}
```

---

### [ä¸¥é‡-08] æ•°ç»„è¶Šç•Œé£é™©

**ä½ç½®**: `src/internal/server/clusterserver/rebalance.go:192-193`

**åˆ†æ**:
```go
for shardID := uint32(0); shardID < uint32(len(newMap.Shards)); shardID++ {
    oldOwner, oldExists := oldMap.GetShard(shardID)
    // ...
}
```

- **é—®é¢˜**:
  - `newMap.Shards` æ˜¯ `map[uint32]string`ï¼Œä¸æ˜¯åˆ‡ç‰‡
  - `len(newMap.Shards)` è¿”å›çš„æ˜¯ **å·²åˆ†é…åˆ†ç‰‡æ•°**ï¼Œä¸æ˜¯ 256
  - è‹¥åªåˆ†é…äº† 10 ä¸ªåˆ†ç‰‡ï¼Œå¾ªç¯åªæ‰§è¡Œ 10 æ¬¡ï¼Œ**æ¼æ£€ 246 ä¸ªåˆ†ç‰‡**

**å»ºè®®**:
```go
func (rm *RebalanceManager) computeMigrations(oldMap, newMap *ShardMap) map[uint32]*MigrationTarget {
    migrations := make(map[uint32]*MigrationTarget)

    // éå†æ‰€æœ‰ 256 ä¸ªåˆ†ç‰‡
    for shardID := uint32(0); shardID < DefaultShardCount; shardID++ {
        oldOwner, oldExists := oldMap.GetShard(shardID)
        newOwner, newExists := newMap.GetShard(shardID)

        if !newExists {
            continue // åˆ†ç‰‡æœªåˆ†é…
        }

        if !oldExists || oldOwner != newOwner {
            migrations[shardID] = &MigrationTarget{
                NodeID: newOwner,
                Addr:   "", // ä»æˆå‘˜åˆ—è¡¨å¡«å……
            }
        }
    }

    return migrations
}
```

---

## âš ï¸ è­¦å‘Šé—®é¢˜ (Warnings)

### [è­¦å‘Š-01] é…ç½®æ ¡éªŒä¸å®Œæ•´

**ä½ç½®**: `src/internal/server/clusterserver/server.go:580-607`

**åˆ†æ**:
- `Config.validate()` æœªæ ¡éªŒä»¥ä¸‹å¿…å¡«å­—æ®µ:
  - `Bootstrap` + `SeedNodes` äº’æ–¥æ€§ï¼ˆBootstrap æ¨¡å¼ä¸åº”æŒ‡å®š SeedNodesï¼‰
  - `ReplicationFactor` ä¸Šé™ï¼ˆä¸åº”è¶…è¿‡é›†ç¾¤èŠ‚ç‚¹æ•°ï¼‰
  - `Storage` åœ¨å¯ç”¨ rebalance æ—¶å¿…å¡«

**å»ºè®®**:
```go
func (cfg *Config) validate() error {
    // ç°æœ‰æ ¡éªŒ...

    // æ–°å¢æ ¡éªŒ
    if cfg.Bootstrap && len(cfg.SeedNodes) > 0 {
        return errors.New("bootstrap mode should not specify seed_nodes")
    }

    if cfg.ReplicationFactor < 1 || cfg.ReplicationFactor > 7 {
        return fmt.Errorf("replication_factor must be 1-7, got %d", cfg.ReplicationFactor)
    }

    // Storage ä¾èµ–æ ¡éªŒ
    if cfg.Rebalance.ConcurrentShards > 0 && cfg.Storage == nil {
        return errors.New("storage is required when rebalance is enabled")
    }

    return nil
}
```

---

### [è­¦å‘Š-02] ç¼ºå°‘å¶æ•°èŠ‚ç‚¹å‘Šè­¦

**ä½ç½®**: `src/internal/server/clusterserver/server.go` (æ•´ä½“é€»è¾‘ç¼ºå¤±)

**åˆ†æ**:
- **è®¾è®¡è¦æ±‚** (RQ-0401 Â§ 1.3.1.1): å¶æ•°èŠ‚ç‚¹æ—¶åº”å‘å‡ºè­¦å‘Š
- **å®é™…ä»£ç **: æœªå®ç°æ£€æµ‹é€»è¾‘
- **å½±å“**: ç”¨æˆ·å¯èƒ½é…ç½® 2/4/6 èŠ‚ç‚¹ï¼Œå¯¼è‡´ç½‘ç»œåˆ†åŒºæ—¶ Quorum ä¸¢å¤±

**å»ºè®®**:
```go
func (s *Server) checkClusterParity() {
    members := s.fsm.GetMembers()
    nodeCount := len(members)

    if nodeCount%2 == 0 {
        s.logger.Warn("cluster has even number of nodes - network partition may cause quorum loss",
            "node_count", nodeCount,
            "recommendation", "use odd numbers (3, 5, 7)")

        // è®¾ç½® metrics
        // tokmesh_cluster_nodes_parity = 1
    }
}

// åœ¨ handleLeaderChange å’Œ member join/leave æ—¶è°ƒç”¨
```

**å¼•ç”¨**: `@req RQ-0401 Â§ 1.3.1.1 å¶æ•°èŠ‚ç‚¹é£é™©æç¤º`

---

### [è­¦å‘Š-03] ç¼ºå°‘ Under-replicated ç›‘æµ‹

**ä½ç½®**: `src/internal/server/clusterserver/` (åŠŸèƒ½ç¼ºå¤±)

**åˆ†æ**:
- **è®¾è®¡è¦æ±‚** (RQ-0401 Â§ 1.3.2): ç›‘æµ‹å‰¯æœ¬æ•°ä½äºé…ç½®å€¼çš„æƒ…å†µ
- **å®é™…ä»£ç **: æœªå®ç°
- **å½±å“**: æ•°æ®ä¸¢å¤±é£é™©æ— æ³•åŠæ—¶å‘ç°

**å»ºè®®**:
```go
// åœ¨ Server ä¸­æ·»åŠ å®šæ—¶æ£€æŸ¥
func (s *Server) monitorReplication() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            s.checkUnderReplicatedShards()
        case <-s.stopCh:
            return
        }
    }
}

func (s *Server) checkUnderReplicatedShards() {
    shardMap := s.GetShardMap()
    targetRF := s.config.ReplicationFactor

    for shardID := uint32(0); shardID < DefaultShardCount; shardID++ {
        actualRF := shardMap.GetReplicationFactor(shardID)
        if actualRF < targetRF {
            s.logger.Warn("shard under-replicated",
                "shard_id", shardID,
                "target_rf", targetRF,
                "actual_rf", actualRF)
            // è§¦å‘å‘Šè­¦
        }
    }
}
```

**å¼•ç”¨**: `@req RQ-0401 Â§ 1.3.2 æ•°æ®é¢ - è¿è¡Œæ—¶å‰¯æœ¬ç›‘æµ‹`

---

### [è­¦å‘Š-04] Nil æŒ‡é’ˆæ£€æŸ¥ç¼ºå¤±

**ä½ç½®**: `src/internal/server/clusterserver/server.go:217-262`

**åˆ†æ**:
```go
func (s *Server) Stop(ctx context.Context) error {
    // ...
    if s.discovery != nil {  // âœ… æœ‰ nil æ£€æŸ¥
        // ...
    }

    if s.raft != nil {  // âœ… æœ‰ nil æ£€æŸ¥
        // ...
    }

    // âŒ ä½† Start() å¤±è´¥æ—¶ï¼Œå¯èƒ½åªåˆå§‹åŒ–äº†éƒ¨åˆ†ç»„ä»¶
    // ä¾‹å¦‚: raft åˆ›å»ºæˆåŠŸï¼Œä½† discovery åˆ›å»ºå¤±è´¥
    // Stop() åº”è¯¥æ›´é˜²å¾¡æ€§åœ°å¤„ç†
}
```

**å»ºè®®**: å·²æœ‰ nil æ£€æŸ¥ï¼Œä½†å»ºè®®åœ¨ `NewServer()` å¤±è´¥æ—¶ä¹Ÿè°ƒç”¨ `Stop()` æ¸…ç†:
```go
func NewServer(cfg Config) (*Server, error) {
    // ...
    s := &Server{...}

    if cfg.Storage != nil {
        rebalanceManager := NewRebalanceManager(...)
        if rebalanceManager == nil {
            s.Stop(context.Background())  // æ¸…ç†å·²åˆ›å»ºçš„èµ„æº
            return nil, errors.New("failed to create rebalance manager")
        }
        s.rebalanceManager = rebalanceManager
    }

    return s, nil
}
```

---

### [è­¦å‘Š-05] é”™è¯¯æ—¥å¿—åç»§ç»­æ‰§è¡Œ

**ä½ç½®**: `src/internal/server/clusterserver/server.go:440-453`

**åˆ†æ**:
```go
if err := s.ApplyMemberJoin(nodeID, addr); err != nil {
    s.logger.Error("failed to apply member join",
        "node_id", nodeID,
        "error", err)
    // âŒ è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œï¼ŒèŠ‚ç‚¹æœªçœŸæ­£åŠ å…¥é›†ç¾¤ä½†å›è°ƒå·²å¤„ç†
}

if err := s.raft.AddVoter(nodeID, addr, 10*time.Second); err != nil {
    s.logger.Error("failed to add voter",
        "node_id", nodeID,
        "error", err)
    // âŒ åŒæ ·çš„é—®é¢˜
}
```

- **å½±å“**:
  - èŠ‚ç‚¹çŠ¶æ€ä¸ä¸€è‡´
  - FSM ä¸­æœ‰æˆå‘˜è®°å½•ï¼Œä½† Raft ä¸­æ— æŠ•ç¥¨æƒ
  - é›†ç¾¤æ‹“æ‰‘æ··ä¹±

**å»ºè®®**:
```go
s.discovery.OnJoin(func(nodeID, addr string) {
    s.logger.Info("discovery: node joined", "node_id", nodeID)

    if !s.IsLeader() {
        return  // ä»… Leader å¤„ç†
    }

    // å…ˆåŠ å…¥ Raft
    if err := s.raft.AddVoter(nodeID, addr, 10*time.Second); err != nil {
        s.logger.Error("failed to add voter - aborting join",
            "node_id", nodeID,
            "error", err)
        return  // âŒ å¤±è´¥åˆ™ç›´æ¥è¿”å›
    }

    // Raft æˆåŠŸåå†æ›´æ–° FSM
    if err := s.ApplyMemberJoin(nodeID, addr); err != nil {
        s.logger.Error("failed to apply member join - removing from raft",
            "node_id", nodeID,
            "error", err)
        // å›æ»š: ä» Raft ç§»é™¤
        s.raft.RemoveServer(nodeID, 10*time.Second)
        return
    }
})
```

---

### [è­¦å‘Š-06] æµæ§é™åˆ¶æœªç”Ÿæ•ˆ

**ä½ç½®**: `src/internal/server/clusterserver/rebalance.go:252`

**åˆ†æ**:
```go
limiter := rate.NewLimiter(rate.Limit(rm.cfg.MaxRateBytesPerSec), int(rm.cfg.MaxRateBytesPerSec))
```

- **é—®é¢˜**:
  - `rate.Limit` çš„å•ä½æ˜¯ **events/second**
  - `Limiter(20971520, 20971520)` è¡¨ç¤ºæ¯ç§’ **2000ä¸‡ä¸ª event**ï¼Œä¸æ˜¯å­—èŠ‚æ•°
  - å®é™…æµæ§æœªç”Ÿæ•ˆ

**å»ºè®®**:
```go
// MaxRateBytesPerSec = 20MB/s = 20 * 1024 * 1024 bytes/s
// ä½¿ç”¨ rate.Every() è®¡ç®—æ¯å­—èŠ‚çš„é—´éš”
bytesPerSec := float64(rm.cfg.MaxRateBytesPerSec)
limiter := rate.NewLimiter(rate.Limit(bytesPerSec), int(bytesPerSec))

// æˆ–è€…ä½¿ç”¨æ›´ç²¾ç¡®çš„æ–¹å¼
limiter := rate.NewLimiter(
    rate.Limit(rm.cfg.MaxRateBytesPerSec),  // æ¯ç§’å…è®¸çš„å­—èŠ‚æ•°
    rm.cfg.MaxRateBytesPerSec,              // Burst å¤§å°
)
```

**å¼•ç”¨**: `@req RQ-0401 Â§ 1.1 - æ•°æ®æ¬è¿ä¼˜åŒ–æµæ§`

---

### [è­¦å‘Š-07] FSM.Apply è¿”å›é”™è¯¯æœªè¢« Raft å¤„ç†

**ä½ç½®**: `src/internal/server/clusterserver/fsm.go:98-126`

**åˆ†æ**:
```go
func (f *FSM) Apply(log *raft.Log) interface{} {
    var entry LogEntry
    if err := json.Unmarshal(log.Data, &entry); err != nil {
        f.logger.Error("failed to unmarshal log entry", "error", err)
        return fmt.Errorf("unmarshal log entry: %w", err)  // è¿”å›é”™è¯¯
    }
    // ...
}
```

- **é—®é¢˜**:
  - Raft çš„ `FSM.Apply()` è¿”å›å€¼ä¼šè¢«å­˜å‚¨ä½†**ä¸å½±å“å…±è¯†**
  - å³ä½¿è¿”å›é”™è¯¯ï¼ŒRaft ä¹Ÿè®¤ä¸ºè¯¥ log å·²æˆåŠŸåº”ç”¨
  - å¯èƒ½å¯¼è‡´èŠ‚ç‚¹é—´çŠ¶æ€ä¸ä¸€è‡´

**å»ºè®®**:
```go
func (f *FSM) Apply(log *raft.Log) interface{} {
    var entry LogEntry
    if err := json.Unmarshal(log.Data, &entry); err != nil {
        f.logger.Error("FATAL: failed to unmarshal log entry", "error", err)
        // ä¸¥é‡é”™è¯¯ - è®°å½•å¹¶ panicï¼ˆè§¦å‘èŠ‚ç‚¹é‡å¯ï¼‰
        panic(fmt.Sprintf("FSM unmarshal failed: %v", err))
    }

    // ... æ­£å¸¸å¤„ç†é€»è¾‘

    // ä»…è¿”å› nil æˆ–ä¸šåŠ¡æ•°æ®ï¼Œä¸è¿”å› error
    return nil
}
```

**åŸå› **: FSM å¿…é¡»æ˜¯ç¡®å®šæ€§çš„ï¼Œç›¸åŒè¾“å…¥å¿…é¡»äº§ç”Ÿç›¸åŒè¾“å‡ºã€‚è§£æå¤±è´¥è¡¨ç¤ºæ•°æ®æŸåï¼Œåº” panic è€Œéé™é»˜å¤±è´¥ã€‚

---

### [è­¦å‘Š-08] Snapshot æœªå‹ç¼©

**ä½ç½®**: `src/internal/server/clusterserver/fsm.go:272-298`

**åˆ†æ**:
```go
func (s *fsmSnapshot) Persist(sink raft.SnapshotSink) error {
    // ...
    encoder := json.NewEncoder(sink)  // âŒ ç›´æ¥ JSON ç¼–ç ï¼Œæœªå‹ç¼©
    if err := encoder.Encode(state); err != nil {
        return fmt.Errorf("encode snapshot: %w", err)
    }
    // ...
}
```

- **å½±å“**:
  - Snapshot æ–‡ä»¶ä½“ç§¯å¤§ï¼ˆå°¤å…¶æ˜¯ members å’Œ shardMap è¾ƒå¤§æ—¶ï¼‰
  - ç½‘ç»œä¼ è¾“æ…¢
  - ç£ç›˜å ç”¨é«˜

**å»ºè®®**:
```go
import (
    "compress/gzip"
    "encoding/json"
)

func (s *fsmSnapshot) Persist(sink raft.SnapshotSink) error {
    err := func() error {
        // ä½¿ç”¨ gzip å‹ç¼©
        gzipWriter := gzip.NewWriter(sink)
        defer gzipWriter.Close()

        encoder := json.NewEncoder(gzipWriter)
        state := struct {
            ShardMap *ShardMap          `json:"shard_map"`
            Members  map[string]*Member `json:"members"`
        }{
            ShardMap: s.shardMap,
            Members:  s.members,
        }

        if err := encoder.Encode(state); err != nil {
            return fmt.Errorf("encode snapshot: %w", err)
        }

        return nil
    }()

    // ...
}

// Restore æ—¶ä¹Ÿéœ€è¦è§£å‹
func (f *FSM) Restore(r io.ReadCloser) error {
    defer r.Close()

    gzipReader, err := gzip.NewReader(r)
    if err != nil {
        return fmt.Errorf("create gzip reader: %w", err)
    }
    defer gzipReader.Close()

    var state struct {
        ShardMap *ShardMap           `json:"shard_map"`
        Members  map[string]*Member  `json:"members"`
    }

    if err := json.NewDecoder(gzipReader).Decode(&state); err != nil {
        return fmt.Errorf("decode snapshot: %w", err)
    }

    // ...
}
```

---

### [è­¦å‘Š-09] Handler æœªæ ¡éªŒ Storage æ˜¯å¦ä¸º nil

**ä½ç½®**: `src/internal/server/clusterserver/handler.go:200-208`

**åˆ†æ**:
```go
if h.server.storage != nil {
    if err := h.server.storage.Create(ctx, &session); err != nil {
        h.logger.Warn("failed to store received session",
            "session_id", session.ID,
            "error", err)
        // Continue even if storage fails
    }
}
```

- **é—®é¢˜**:
  - Storage ä¸º nil æ—¶ï¼ŒTransferShard ä¼š**é™é»˜ä¸¢å¼ƒ**æ‰€æœ‰æ¥æ”¶çš„æ•°æ®
  - æ²¡æœ‰è¿”å›é”™è¯¯ç»™å®¢æˆ·ç«¯
  - æ•°æ®è¿ç§»"æˆåŠŸ"ä½†å®é™…æœªä¿å­˜

**å»ºè®®**:
```go
// åœ¨ TransferShard å¼€å§‹æ—¶æ£€æŸ¥
func (h *Handler) TransferShard(...) (*connect.Response[v1.TransferShardResponse], error) {
    // å‰ç½®æ£€æŸ¥
    if h.server.storage == nil {
        h.logger.Error("transfer shard rejected - storage not configured")
        return nil, connect.NewError(connect.CodeFailedPrecondition,
            errors.New("storage engine not available"))
    }

    // ...

    // å­˜å‚¨å¤±è´¥æ—¶ä¹Ÿåº”è¿”å›é”™è¯¯
    if err := h.server.storage.Create(ctx, &session); err != nil {
        h.logger.Error("failed to store session",
            "session_id", session.ID,
            "error", err)
        return nil, connect.NewError(connect.CodeInternal,
            fmt.Errorf("storage failed: %w", err))
    }
}
```

---

### [è­¦å‘Š-10] LeaderCh æ³„æ¼é£é™©

**ä½ç½®**: `src/internal/server/clusterserver/raft.go:284`

**åˆ†æ**:
```go
func (n *RaftNode) Close() error {
    // ...
    close(n.leaderCh)  // âŒ åœ¨ Shutdown åå…³é—­
    // ...
}
```

- **é—®é¢˜**:
  - Raft Shutdown åï¼Œ`NotifyCh` å¯èƒ½è¿˜ä¼šå‘é€äº‹ä»¶
  - è¿‡æ—©å…³é—­ `leaderCh` å¯èƒ½å¯¼è‡´ Raft åº“ panic
  - æ­£ç¡®é¡ºåºåº”è¯¥æ˜¯: å…ˆåœæ­¢å‘é€è€…ï¼Œå†å…³é—­ channel

**å»ºè®®**:
```go
func (n *RaftNode) Close() error {
    n.logger.Info("shutting down raft node")

    // 1. å…ˆåœæ­¢ Raftï¼ˆåœæ­¢å‘é€åˆ° NotifyChï¼‰
    shutdownFuture := n.raft.Shutdown()
    if err := shutdownFuture.Error(); err != nil {
        n.logger.Error("raft shutdown failed", "error", err)
    }

    // 2. ç­‰å¾… Shutdown å®Œæˆåå†å…³é—­ channel
    close(n.leaderCh)

    // 3. å…³é—­å­˜å‚¨
    // ...
}
```

---

### [è­¦å‘Š-11] æ•°æ®è¿ç§»æœªæ¸…ç†æºèŠ‚ç‚¹æ•°æ®

**ä½ç½®**: `src/internal/server/clusterserver/rebalance.go:218-363`

**åˆ†æ**:
- **è®¾è®¡è¦æ±‚** (RQ-0401): "è¿ç§»å®Œæˆåï¼Œæ–°èŠ‚ç‚¹æ•°æ®ç«‹å³å¯ç”¨"
- **å®é™…ä»£ç **: `migrateShardData()` æˆåŠŸåæœªåˆ é™¤æºèŠ‚ç‚¹æ•°æ®
- **å½±å“**:
  - æ•°æ®å†—ä½™
  - å†…å­˜å ç”¨ç¿»å€
  - æ—§èŠ‚ç‚¹å¯èƒ½ç»§ç»­æœåŠ¡è¿‡æ—¶æ•°æ®

**å»ºè®®**:
```go
func (rm *RebalanceManager) migrateShardData(ctx context.Context, shardID uint32) error {
    // ... è¿ç§»é€»è¾‘

    // è¿ç§»æˆåŠŸååˆ é™¤æœ¬åœ°æ•°æ®
    if err := rm.cleanupShardData(ctx, shardID); err != nil {
        rm.logger.Error("failed to cleanup shard data",
            "shard_id", shardID,
            "error", err)
        // ä¸å½±å“è¿ç§»æˆåŠŸçŠ¶æ€ï¼Œä½†è®°å½•å‘Šè­¦
    }

    return nil
}

func (rm *RebalanceManager) cleanupShardData(ctx context.Context, shardID uint32) error {
    deletedCount := 0

    rm.storage.Scan(func(sess *domain.Session) bool {
        if sess.ShardID != shardID {
            return true
        }

        if err := rm.storage.Delete(ctx, sess.ID); err != nil {
            rm.logger.Warn("failed to delete session",
                "session_id", sess.ID,
                "error", err)
        } else {
            deletedCount++
        }

        return true
    })

    rm.logger.Info("shard data cleanup completed",
        "shard_id", shardID,
        "deleted_count", deletedCount)

    return nil
}
```

---

### [è­¦å‘Š-12] RPC è¶…æ—¶é…ç½®ç¡¬ç¼–ç 

**ä½ç½®**: å¤šå¤„ (server.go, handler.go)

**åˆ†æ**:
```go
// server.go:313, 349, 376
s.raft.Apply(data, 5*time.Second)

// server.go:447, 469, 76
s.raft.AddVoter(nodeID, addr, 10*time.Second)

// handler.go:76
s.raft.AddVoter(req.Msg.NodeId, req.Msg.AdvertiseAddress, 10*time.Second)
```

- **é—®é¢˜**:
  - è¶…æ—¶æ—¶é—´ç¡¬ç¼–ç ï¼Œæ— æ³•æ ¹æ®ç½‘ç»œç¯å¢ƒè°ƒæ•´
  - å¤§å‹é›†ç¾¤ (100+ èŠ‚ç‚¹) å¯èƒ½éœ€è¦æ›´é•¿è¶…æ—¶

**å»ºè®®**:
```go
type Config struct {
    // ...

    // Raft operation timeouts
    RaftApplyTimeout     time.Duration  // default: 5s
    RaftMembershipTimeout time.Duration  // default: 10s
}

func (cfg *Config) validate() error {
    // ...

    // è®¾ç½®é»˜è®¤å€¼
    if cfg.RaftApplyTimeout == 0 {
        cfg.RaftApplyTimeout = 5 * time.Second
    }
    if cfg.RaftMembershipTimeout == 0 {
        cfg.RaftMembershipTimeout = 10 * time.Second
    }

    return nil
}

// ä½¿ç”¨é…ç½®å€¼
s.raft.Apply(data, s.config.RaftApplyTimeout)
s.raft.AddVoter(nodeID, addr, s.config.RaftMembershipTimeout)
```

---

## ğŸ’¡ å»ºè®®é—®é¢˜ (Suggestions)

### [å»ºè®®-01] é­”æœ¯å€¼æœªå®šä¹‰ä¸ºå¸¸é‡

**ä½ç½®**: å¤šå¤„

**é­”æœ¯å€¼æ¸…å•**:
```go
// shard.go:18
DefaultVirtualNodeCount = 100  // åº”ä¸º 256

// raft.go:78-81
HeartbeatTimeout = 1000 * time.Millisecond
ElectionTimeout = 1000 * time.Millisecond
CommitTimeout = 50 * time.Millisecond
LeaderLeaseTimeout = 500 * time.Millisecond

// server.go:203
waitForLeader(ctx, 10*time.Second)

// server.go:256
time.After(5 * time.Second)

// rebalance.go:246
10*time.Minute

// handler.go:76, 447
10*time.Second
```

**å»ºè®®**: å®šä¹‰é…ç½®å¸¸é‡
```go
const (
    // Shard configuration
    DefaultShardCount       = 256
    DefaultVirtualNodeCount = 256

    // Raft timing
    DefaultRaftHeartbeatTimeout   = 1000 * time.Millisecond
    DefaultRaftElectionTimeout    = 1000 * time.Millisecond
    DefaultRaftCommitTimeout      = 50 * time.Millisecond
    DefaultRaftLeaderLeaseTimeout = 500 * time.Millisecond

    // Cluster operations
    DefaultLeaderElectionTimeout = 10 * time.Second
    DefaultRebalanceStabilizationDelay = 5 * time.Second
    DefaultRebalanceTimeout = 10 * time.Minute
    DefaultMembershipChangeTimeout = 10 * time.Second
)
```

---

### [å»ºè®®-02] æ—¥å¿—çº§åˆ«ä¸ä¸€è‡´

**ä½ç½®**: å¤šå¤„

**é—®é¢˜**:
```go
// server.go:440 - èŠ‚ç‚¹åŠ å…¥å¤±è´¥ç”¨ Error
s.logger.Error("failed to apply member join", ...)

// discovery.go:191 - èŠ‚ç‚¹åŠ å…¥æ—  Raft å…ƒæ•°æ®ç”¨ Warn
e.discovery.logger.Warn("node joined without Raft metadata", ...)

// handler.go:206 - å­˜å‚¨ä¼šè¯å¤±è´¥ç”¨ Warn
h.logger.Warn("failed to store received session", ...)
```

- **å½±å“**: å‘Šè­¦çº§åˆ«æ··ä¹±ï¼Œç›‘æ§è§„åˆ™éš¾ä»¥è®¾ç½®

**å»ºè®®**: ç»Ÿä¸€æ—¥å¿—çº§åˆ«è§„èŒƒ
- **Error**: å½±å“æ ¸å¿ƒåŠŸèƒ½çš„ä¸¥é‡é”™è¯¯ï¼ˆèŠ‚ç‚¹åŠ å…¥å¤±è´¥ã€Raft åº”ç”¨å¤±è´¥ï¼‰
- **Warn**: éƒ¨åˆ†å¤±è´¥ä½†ç³»ç»Ÿå¯ç»§ç»­è¿è¡Œï¼ˆå‰¯æœ¬å¤åˆ¶å»¶è¿Ÿã€å•ä¸ªä¼šè¯å­˜å‚¨å¤±è´¥ï¼‰
- **Info**: æ­£å¸¸è¿ç»´äº‹ä»¶ï¼ˆèŠ‚ç‚¹åŠ å…¥æˆåŠŸã€Leader é€‰ä¸¾å®Œæˆï¼‰
- **Debug**: è°ƒè¯•ä¿¡æ¯ï¼ˆRPC è¯·æ±‚è¯¦æƒ…ã€Gossip å¿ƒè·³ï¼‰

---

### [å»ºè®®-03] ç¼ºå°‘ Metrics æš´éœ²

**ä½ç½®**: æ•´ä¸ªæ¨¡å—

**åˆ†æ**:
- è®¾è®¡æ–‡æ¡£è¦æ±‚å¯è§‚æµ‹æ€§ï¼Œä½†ä»£ç æœªæš´éœ²ä»»ä½• Prometheus metrics
- å…³é”®æŒ‡æ ‡ç¼ºå¤±:
  - `tokmesh_cluster_nodes_total`
  - `tokmesh_cluster_nodes_parity`
  - `tokmesh_cluster_leader_changes_total`
  - `tokmesh_cluster_rebalance_duration_seconds`
  - `tokmesh_cluster_shard_migrations_total`

**å»ºè®®**: é›†æˆ Prometheus
```go
import "github.com/prometheus/client_golang/prometheus"

var (
    clusterNodesTotal = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "tokmesh_cluster_nodes_total",
            Help: "Current number of cluster nodes",
        },
    )

    clusterLeaderChanges = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: "tokmesh_cluster_leader_changes_total",
            Help: "Total number of leader changes",
        },
    )

    // ... æ›´å¤šæŒ‡æ ‡
)

func init() {
    prometheus.MustRegister(clusterNodesTotal)
    prometheus.MustRegister(clusterLeaderChanges)
}

func (s *Server) updateMetrics() {
    members := s.fsm.GetMembers()
    clusterNodesTotal.Set(float64(len(members)))
}
```

---

### [å»ºè®®-04] ç¼ºå°‘å•å…ƒæµ‹è¯•è¦†ç›–

**ä½ç½®**: æµ‹è¯•æ–‡ä»¶

**åˆ†æ**:
- æµ‹è¯•æ–‡ä»¶å…± 4060 è¡Œï¼Œä½†æœªæ£€æŸ¥è¦†ç›–ç‡
- å…³é”®è·¯å¾„å¯èƒ½æœªè¦†ç›–:
  - Config.validate() è¾¹ç•Œæƒ…å†µ
  - ShardMap.computeMigrations() ç®—æ³•æ­£ç¡®æ€§
  - FSM.Apply() å„ç§ LogEntryType
  - AuthInterceptor mTLS éªŒè¯

**å»ºè®®**:
```bash
# æ£€æŸ¥è¦†ç›–ç‡
go test -coverprofile=coverage.out ./internal/server/clusterserver
go tool cover -html=coverage.out

# ç›®æ ‡: è¦†ç›–ç‡ â‰¥ 80%
```

---

### [å»ºè®®-05] æ–‡æ¡£æ³¨é‡Šä¸è§„èŒƒ

**ä½ç½®**: å¤šå¤„

**é—®é¢˜**:
```go
// âŒ ä¸è§„èŒƒ
// Join handles the Join RPC.
//
// Allows a new node to join the cluster.

// âœ… è§„èŒƒï¼ˆåº”è¯¥æ›´è¯¦ç»†ï¼‰
// Join handles the Join RPC request from a new node.
//
// This method:
//  1. Validates the request (only leader can accept joins)
//  2. Adds the node to Raft cluster as a voter
//  3. Applies member join event through Raft FSM
//  4. Returns current cluster state (members + shard map)
//
// Returns:
//  - Accepted=true + cluster state if successful
//  - Accepted=false + leader redirect if not leader
//  - Error if internal failure occurs
```

**å»ºè®®**: è¡¥å……è¯¦ç»†æ–‡æ¡£ï¼Œå°¤å…¶æ˜¯:
- å…¬å…± API çš„å®Œæ•´æ–‡æ¡£
- å¹¶å‘å®‰å…¨æ€§è¯´æ˜
- é”™è¯¯åœºæ™¯å¤„ç†

---

### [å»ºè®®-06] é…ç½®ç»“æ„åµŒå¥—è¿‡æ·±

**ä½ç½®**: `server.go:58-86`

**åˆ†æ**:
```go
type Config struct {
    NodeID             string
    RaftBindAddr       string
    GossipBindAddr     string
    GossipBindPort     int
    Bootstrap          bool
    SeedNodes          []string
    RaftDataDir        string
    ReplicationFactor  int
    Storage            *storage.Engine
    Rebalance          RebalanceConfig  // åµŒå¥—
    Logger             *slog.Logger
}
```

- **é—®é¢˜**: é…ç½®é¡¹æ‰å¹³åŒ–ï¼Œæœªåˆ†ç»„
- **å½±å“**: å¤§å‹é…ç½®æ–‡ä»¶éš¾ä»¥ç»´æŠ¤

**å»ºè®®**:
```go
type Config struct {
    Node       NodeConfig
    Raft       RaftConfig
    Gossip     GossipConfig
    Data       DataConfig
    Rebalance  RebalanceConfig
    Logger     *slog.Logger
}

type NodeConfig struct {
    ID              string
    Bootstrap       bool
    AdvertiseAddr   string
}

type RaftConfig struct {
    BindAddr string
    DataDir  string
    Timeouts RaftTimeouts
}

type GossipConfig struct {
    BindAddr  string
    BindPort  int
    SeedNodes []string
}

type DataConfig struct {
    Storage           *storage.Engine
    ReplicationFactor int
}
```

---

### [å»ºè®®-07] ç¼ºå°‘é›†æˆæµ‹è¯•

**ä½ç½®**: æµ‹è¯•ç­–ç•¥

**åˆ†æ**:
- ç°æœ‰æµ‹è¯•å¯èƒ½æ˜¯å•å…ƒæµ‹è¯•
- éœ€è¦ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•éªŒè¯:
  - 3èŠ‚ç‚¹é›†ç¾¤å¯åŠ¨ + Leader é€‰ä¸¾
  - èŠ‚ç‚¹åŠ¨æ€åŠ å…¥/ç¦»å¼€
  - æ•°æ®è¿ç§»å®Œæ•´æ€§
  - ç½‘ç»œåˆ†åŒºæ¢å¤
  - mTLS è®¤è¯

**å»ºè®®**: ä½¿ç”¨ Docker Compose æˆ– Testcontainers
```go
// integration_test.go
func TestClusterBootstrap(t *testing.T) {
    // å¯åŠ¨ 3 ä¸ªèŠ‚ç‚¹
    nodes := startCluster(t, 3)
    defer stopCluster(nodes)

    // éªŒè¯ Leader é€‰ä¸¾
    leader := waitForLeader(t, nodes, 10*time.Second)
    require.NotNil(t, leader)

    // éªŒè¯ Shard Map åŒæ­¥
    for _, node := range nodes {
        shardMap := node.GetShardMap()
        assert.Equal(t, leader.GetShardMap().Version, shardMap.Version)
    }
}
```

---

## âœ… é€šè¿‡é¡¹ï¼ˆPassed Itemsï¼‰

ä»¥ä¸‹æ–¹é¢å®ç°è‰¯å¥½:

1. âœ… **é”™è¯¯åŒ…è£…**: ä½¿ç”¨ `fmt.Errorf("op: %w", err)` åŒ…è£…é”™è¯¯
2. âœ… **å¹¶å‘é”ä½¿ç”¨**: ShardMap, FSM, Server æ­£ç¡®ä½¿ç”¨ RWMutex
3. âœ… **èµ„æºæ¸…ç†**: Raft.Close() æ­£ç¡®å…³é—­æ‰€æœ‰èµ„æº
4. âœ… **Panic æ¢å¤**: RecoveryInterceptor æ•è· RPC panic
5. âœ… **ç»“æ„åŒ–æ—¥å¿—**: ä½¿ç”¨ slog è€Œé fmt.Println
6. âœ… **Context ä¼ æ’­**: RPC æ–¹æ³•æ­£ç¡®ä½¿ç”¨ Context
7. âœ… **Clone æ–¹æ³•**: ShardMap.Clone() æ­£ç¡®æ·±æ‹·è´

---

## ğŸ“‹ é—®é¢˜ä¼˜å…ˆçº§æ’åº

### P0 - å¿…é¡»ç«‹å³ä¿®å¤ï¼ˆé˜»å¡å‘å¸ƒï¼‰

1. **[ä¸¥é‡-01]** è™šæ‹ŸèŠ‚ç‚¹æ•°ä¸è®¾è®¡ä¸ä¸€è‡´
2. **[ä¸¥é‡-02]** å“ˆå¸Œç®—æ³•ä¸è®¾è®¡ä¸ä¸€è‡´
3. **[ä¸¥é‡-03]** ç¼ºå°‘ Cluster ID æ ¡éªŒ
4. **[ä¸¥é‡-04]** mTLS è®¤è¯æœªå®ç°
5. **[ä¸¥é‡-05]** ç”Ÿäº§ç¯å¢ƒ TLS é…ç½®ç¼ºå¤±
6. **[ä¸¥é‡-08]** æ•°ç»„è¶Šç•Œé£é™©

### P1 - åº”è¯¥å°½å¿«ä¿®å¤ï¼ˆå½±å“ç¨³å®šæ€§ï¼‰

7. **[ä¸¥é‡-06]** Goroutine æ³„æ¼é£é™©
8. **[ä¸¥é‡-07]** Channel åŒé‡å…³é—­é£é™©
9. **[è­¦å‘Š-05]** é”™è¯¯æ—¥å¿—åç»§ç»­æ‰§è¡Œ
10. **[è­¦å‘Š-06]** æµæ§é™åˆ¶æœªç”Ÿæ•ˆ
11. **[è­¦å‘Š-09]** Handler æœªæ ¡éªŒ Storage

### P2 - å»ºè®®ä¿®å¤ï¼ˆæå‡è´¨é‡ï¼‰

12. **[è­¦å‘Š-01]** é…ç½®æ ¡éªŒä¸å®Œæ•´
13. **[è­¦å‘Š-02]** ç¼ºå°‘å¶æ•°èŠ‚ç‚¹å‘Šè­¦
14. **[è­¦å‘Š-03]** ç¼ºå°‘ Under-replicated ç›‘æµ‹
15. **[è­¦å‘Š-11]** æ•°æ®è¿ç§»æœªæ¸…ç†æºæ•°æ®
16. **[å»ºè®®-03]** ç¼ºå°‘ Metrics æš´éœ²

---

## ğŸ¯ æ€»ç»“ä¸è¡ŒåŠ¨å»ºè®®

### æ ¸å¿ƒé—®é¢˜

1. **è§„çº¦å¯¹é½ä¸¥é‡åå·®** (P0)
   - è™šæ‹ŸèŠ‚ç‚¹æ•°: 100 â†’ 256
   - å“ˆå¸Œç®—æ³•: FNV â†’ MurmurHash3
   - Cluster ID æ ¡éªŒæœºåˆ¶ç¼ºå¤±

2. **å®‰å…¨æ€§å®ç°ä¸å®Œæ•´** (P0)
   - mTLS è®¤è¯é€»è¾‘æœ‰bug
   - ç”Ÿäº§ç¯å¢ƒä»ä½¿ç”¨æ˜æ–‡ HTTP

3. **å¹¶å‘å®‰å…¨éšæ‚£** (P1)
   - Goroutine ç”Ÿå‘½å‘¨æœŸç®¡ç†ä¸å½“
   - Channel å…³é—­é€»è¾‘æœ‰ç«æ€

### ä¿®å¤è·¯å¾„

**é˜¶æ®µ1: ç´§æ€¥ä¿®å¤** (1-2å¤©)
- ä¿®æ”¹è™šæ‹ŸèŠ‚ç‚¹æ•°å’Œå“ˆå¸Œç®—æ³•
- ä¿®å¤ mTLS è®¤è¯é€»è¾‘
- ä¿®å¤æ•°ç»„è¶Šç•Œå’Œ Channel å…³é—­é—®é¢˜

**é˜¶æ®µ2: ç¨³å®šæ€§å¢å¼º** (3-5å¤©)
- å®ç° Cluster ID æ ¡éªŒ
- æ·»åŠ å¶æ•°èŠ‚ç‚¹å‘Šè­¦
- å®Œå–„é”™è¯¯å¤„ç†å’Œèµ„æºæ¸…ç†

**é˜¶æ®µ3: è´¨é‡æå‡** (1å‘¨)
- æ·»åŠ  Prometheus metrics
- è¡¥å……å•å…ƒæµ‹è¯•è¦†ç›–ç‡
- ç¼–å†™é›†æˆæµ‹è¯•

### æ˜¯å¦å»ºè®®åˆå¹¶

**âŒ ä¸å»ºè®®ç›´æ¥åˆå¹¶åˆ°ç”Ÿäº§ç¯å¢ƒ**

**ç†ç”±**:
1. æ ¸å¿ƒç®—æ³•ä¸è®¾è®¡æ–‡æ¡£ä¸¥é‡ä¸ä¸€è‡´ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®è·¯ç”±é”™è¯¯
2. mTLS è®¤è¯æœªå·¥ä½œï¼Œé›†ç¾¤é—´é€šä¿¡æ— å®‰å…¨ä¿éšœ
3. å­˜åœ¨å¤šä¸ªä¸¥é‡å¹¶å‘é—®é¢˜ï¼Œå¯èƒ½å¯¼è‡´èŠ‚ç‚¹å´©æºƒ

**å»ºè®®**:
- å…ˆä¿®å¤ P0 çº§åˆ«çš„ 6 ä¸ªä¸¥é‡é—®é¢˜
- è¡¥å……é›†æˆæµ‹è¯•éªŒè¯ä¿®å¤æ•ˆæœ
- è¿›è¡Œå‹åŠ›æµ‹è¯•éªŒè¯ç¨³å®šæ€§
- é€šè¿‡å¤æ ¸åå†åˆå¹¶

---

## ğŸ“ é™„å½•

### A. è§„çº¦å¼•ç”¨å®Œæ•´æ€§

å·²éªŒè¯çš„è§„çº¦å¼•ç”¨:
- âœ… `@req RQ-0401` - å­˜åœ¨ä¸”å†…å®¹åŒ¹é…
- âœ… `@design DS-0401` - å­˜åœ¨ä¸”å†…å®¹åŒ¹é…

æœªæ‰¾åˆ°çš„è§„çº¦å¼•ç”¨: æ— 

### B. ä»£ç ç»Ÿè®¡

| æ–‡ä»¶ | ä»£ç è¡Œæ•° | æ³¨é‡Šè¡Œæ•° | ç©ºç™½è¡Œæ•° |
|------|---------|---------|---------|
| server.go | 644 | 89 | 71 |
| raft.go | 342 | 58 | 39 |
| fsm.go | 304 | 45 | 32 |
| discovery.go | 270 | 42 | 28 |
| shard.go | 259 | 38 | 27 |
| rebalance.go | 401 | 62 | 45 |
| handler.go | 268 | 41 | 29 |
| interceptor.go | 385 | 67 | 43 |
| doc.go | 14 | 14 | 0 |
| **æ€»è®¡** | **2887** | **456** | **314** |

### C. ä¾èµ–åˆ†æ

å¤–éƒ¨ä¾èµ–:
- âœ… `github.com/hashicorp/raft` - Raft å…±è¯†ç®—æ³•
- âœ… `github.com/hashicorp/memberlist` - Gossip åè®®
- âœ… `github.com/hashicorp/raft-boltdb` - Raft å­˜å‚¨
- âœ… `connectrpc.com/connect` - RPC æ¡†æ¶
- âš ï¸ **ç¼ºå°‘**: `github.com/spaolacci/murmur3` - éœ€æ·»åŠ ï¼ˆä¿®å¤ä¸¥é‡-02ï¼‰

### D. æµ‹è¯•è¦†ç›–ç‡å»ºè®®

å…³é”®æµ‹è¯•åœºæ™¯ï¼ˆå¾…è¡¥å……ï¼‰:
1. **Config.validate()**
   - ç©ºå€¼æ ¡éªŒ
   - Bootstrap + SeedNodes äº’æ–¥
   - ReplicationFactor è¾¹ç•Œ

2. **ShardMap**
   - HashKey() åˆ†å¸ƒå‡åŒ€æ€§
   - AddNode/RemoveNode æ­£ç¡®æ€§
   - Clone() æ·±æ‹·è´éªŒè¯

3. **FSM**
   - å„ç§ LogEntryType å¤„ç†
   - Snapshot/Restore å¾€è¿”æµ‹è¯•
   - å¹¶å‘å®‰å…¨æ€§

4. **Rebalance**
   - computeMigrations() ç®—æ³•æ­£ç¡®æ€§
   - migrateShardData() æµæ§ç”Ÿæ•ˆ
   - TTL è¿‡æ»¤é€»è¾‘

5. **é›†æˆæµ‹è¯•**
   - 3èŠ‚ç‚¹é›†ç¾¤å¯åŠ¨
   - èŠ‚ç‚¹åŠ¨æ€åŠ å…¥/ç¦»å¼€
   - æ•°æ®è¿ç§»å®Œæ•´æ€§
   - mTLS è®¤è¯

---

**ç”Ÿæˆå·¥å…·**: Claude Code (å®¡æ ¸ä»£ç†)
**å®¡æ ¸æ ‡å‡†**: specs/governance/audit-framework.md v1.1
**ä¸‹ä¸€æ­¥**: ç­‰å¾…å¼€å‘è€…ä¿®å¤åå¤æ ¸
